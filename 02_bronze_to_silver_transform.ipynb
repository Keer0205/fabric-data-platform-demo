{"cells":[{"cell_type":"code","source":["# Read the bronze table\n","df = spark.read.table(\"trips_raw\")\n","print(f\"Raw rows loaded: {df.count():,}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"20696812-f948-4ec7-8006-712fa740f234","normalized_state":"finished","queued_time":"2025-11-17T11:12:36.5562067Z","session_start_time":null,"execution_start_time":"2025-11-17T11:12:36.5573653Z","execution_finish_time":"2025-11-17T11:12:39.0309763Z","parent_msg_id":"575a0fef-6af3-4bc1-88c0-a518352e7ee7"},"text/plain":"StatementMeta(, 20696812-f948-4ec7-8006-712fa740f234, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Raw rows loaded: 68,211\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fda7effe-39ab-42e9-b5c4-2a9ddcfa082e"},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","df_silver = (df\n","    .filter((F.col(\"total_amount\") > 0) & (F.col(\"trip_distance\") > 0))\n","    .select(\n","        F.col(\"VendorID\").alias(\"vendor_id\"),\n","        F.col(\"tpep_pickup_datetime\").alias(\"pickup_datetime\"),\n","        F.col(\"tpep_dropoff_datetime\").alias(\"dropoff_datetime\"),\n","        \"passenger_count\",\n","        \"trip_distance\",\n","        F.col(\"PULocationID\").alias(\"pickup_location_id\"),\n","        F.col(\"DOLocationID\").alias(\"dropoff_location_id\"),\n","        \"fare_amount\",\n","        \"total_amount\"\n","    )\n",")\n","print(\"Transformations applied\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"20696812-f948-4ec7-8006-712fa740f234","normalized_state":"finished","queued_time":"2025-11-17T11:11:04.8836139Z","session_start_time":null,"execution_start_time":"2025-11-17T11:11:37.526849Z","execution_finish_time":"2025-11-17T11:11:39.1462509Z","parent_msg_id":"04468beb-830b-4904-a898-58b95ca12560"},"text/plain":"StatementMeta(, 20696812-f948-4ec7-8006-712fa740f234, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"error","ename":"AnalysisException","evalue":"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tpep_pickup_datetime` cannot be resolved. Did you mean one of the following? [`lpep_pickup_datetime`, `lpep_dropoff_datetime`, `ehail_fee`, `tip_amount`, `trip_distance`].;\n'Project [VendorID#756L AS vendor_id#1140L, 'tpep_pickup_datetime AS pickup_datetime#1141, 'tpep_dropoff_datetime AS dropoff_datetime#1142, passenger_count#763, trip_distance#764, PULocationID#761L AS pickup_location_id#1143L, DOLocationID#762L AS dropoff_location_id#1144L, fare_amount#765, total_amount#772]\n+- Filter ((total_amount#772 > cast(0 as double)) AND (trip_distance#764 > cast(0 as double)))\n   +- SubqueryAlias spark_catalog.lh_taxi_demo.trips_raw\n      +- Relation spark_catalog.lh_taxi_demo.trips_raw[VendorID#756L,lpep_pickup_datetime#757,lpep_dropoff_datetime#758,store_and_fwd_flag#759,RatecodeID#760,PULocationID#761L,DOLocationID#762L,passenger_count#763,trip_distance#764,fare_amount#765,extra#766,mta_tax#767,tip_amount#768,tolls_amount#769,ehail_fee#770,improvement_surcharge#771,total_amount#772,payment_type#773,trip_type#774,congestion_surcharge#775] parquet\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      3\u001b[0m df_silver \u001b[38;5;241m=\u001b[39m (df\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter((F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      6\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVendorID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvendor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpep_pickup_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpep_dropoff_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropoff_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassenger_count\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPULocationID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_location_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOLocationID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropoff_location_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformations applied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jcols(\u001b[38;5;241m*\u001b[39mcols))\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tpep_pickup_datetime` cannot be resolved. Did you mean one of the following? [`lpep_pickup_datetime`, `lpep_dropoff_datetime`, `ehail_fee`, `tip_amount`, `trip_distance`].;\n'Project [VendorID#756L AS vendor_id#1140L, 'tpep_pickup_datetime AS pickup_datetime#1141, 'tpep_dropoff_datetime AS dropoff_datetime#1142, passenger_count#763, trip_distance#764, PULocationID#761L AS pickup_location_id#1143L, DOLocationID#762L AS dropoff_location_id#1144L, fare_amount#765, total_amount#772]\n+- Filter ((total_amount#772 > cast(0 as double)) AND (trip_distance#764 > cast(0 as double)))\n   +- SubqueryAlias spark_catalog.lh_taxi_demo.trips_raw\n      +- Relation spark_catalog.lh_taxi_demo.trips_raw[VendorID#756L,lpep_pickup_datetime#757,lpep_dropoff_datetime#758,store_and_fwd_flag#759,RatecodeID#760,PULocationID#761L,DOLocationID#762L,passenger_count#763,trip_distance#764,fare_amount#765,extra#766,mta_tax#767,tip_amount#768,tolls_amount#769,ehail_fee#770,improvement_surcharge#771,total_amount#772,payment_type#773,trip_type#774,congestion_surcharge#775] parquet\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bda8c21d-3ec4-41e8-9464-1df15dd48bb1"},{"cell_type":"code","source":["# Write as Delta table in silver layer\n","df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.fact_trips\")\n","print(\"Silver table 'silver.fact_trips' created successfully!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"20696812-f948-4ec7-8006-712fa740f234","normalized_state":"cancelled","queued_time":"2025-11-17T11:11:04.8853222Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-11-17T11:11:39.1482086Z","parent_msg_id":"ef1169be-2e57-4944-9c3a-565745c9cfd2"},"text/plain":"StatementMeta(, 20696812-f948-4ec7-8006-712fa740f234, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fa23bdbe-4639-4869-8828-7091a654dd01"},{"cell_type":"code","source":["row_count = spark.table(\"silver.fact_trips\").count()\n","assert row_count > 2_800_000, f\"Only {row_count} rows â€” something wrong!\"\n","print(f\"TEST PASSED: {row_count:,} rows in silver.fact_trips\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"20696812-f948-4ec7-8006-712fa740f234","normalized_state":"cancelled","queued_time":"2025-11-17T11:11:04.8868963Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-11-17T11:11:39.1485394Z","parent_msg_id":"2529dd16-4f86-4c50-85db-434b294ea1c9"},"text/plain":"StatementMeta(, 20696812-f948-4ec7-8006-712fa740f234, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"baf1c872-809a-4abe-973a-9536c835c0d6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"778a53c2-6fdd-4684-9c07-19c825422c40"}],"default_lakehouse":"778a53c2-6fdd-4684-9c07-19c825422c40","default_lakehouse_name":"lh_taxi_demo","default_lakehouse_workspace_id":"44b19c47-bcb5-4166-82d5-484cdb2d2b6c"}}},"nbformat":4,"nbformat_minor":5}